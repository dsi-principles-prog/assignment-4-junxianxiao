---
title: "assign4-part2-data-analyse"
output: html_notebook
---

# Part 2


Choose a dataset (this can be the same dataset as the last assignment, or a new one). Define a predictive modeling problem. Create the appropriate files and notebooks to do the following:

##1. Describe the data and the problem

The dataset I choose is Japan Hostel Dataset, which has 342 hostels in Japan. It includes 16 columns:
hostel number: hostel's number
hostel.name: name of hostel
City: location of hostel
price.from: price of hostel
Distance: distance from hostel to city centre
summary.score: overall score of hostel
rating.band: rating band of hostel, which includes "Superb", "Fabulous", "Very Good", "Good" and "Rating"
atmosphere: rating of atmosphere in hostel
cleanliness: rating of cleanliness of hostel
facilities: quality of hostel's facilities
location.y: rating of hostel's location
security: rating of surrounding and hostel security
staff: rating of staff
valueformoney: whether it is worthwhile to choose the hostel
lon: longitude of hostel
lat: latitude of hostel

Since the helding of 2020 Tokyo Olympic Game, tourists' interests about visiting Japan is increasing. However, the price of hotels in Japan are not friendly. Therefore hostels are a suitable choise for tourists because of its friendly price. 
In this assignment, I want to accomplish a dataset to help me conduct research in the relationship between hostel's overall score and other rating in different city.

##2. Read in and check data

```{r brief view of data}
# show first 6 rows of data 
head(Hostel)
```
```{r check data}
# detect the attribute of each column
str(Hostel)
```
```{r detect null and NA value}
# detect null value
is.null(Hostel)

# detect NA value
Hostel %>% 
  verify(!is.na(.))
```
Therefore the dataset has 0 null value and 223 NA values.

```{r check extreme value in 8 rating columns}
Hostel%>%
  assert(within_bounds(0,10),summary.score)%>% # check if there exist extreme value in summary.score
  assert(within_bounds(0,10),atmosphere)%>% # check if there exist extreme value in atmosphere
  assert(within_bounds(0,10),cleanliness)%>% # check if there exist extreme value in cleanliness
  assert(within_bounds(0,10),facilities)%>% # check if there exist extreme value in facilities
  assert(within_bounds(0,10),location.y)%>% # check if there exist extreme value in location.y
  assert(within_bounds(0,10),security)%>% # check if there exist extreme value in security
  assert(within_bounds(0,10),staff)%>% # check if there exist extreme value in staff
  assert(within_bounds(0,10),valueformoney) # check if there exist extreme value in valueformoney
```
The result shows that there are not any extreme value in 8 rating columns.

##3. Clean up the data. 

In last chunk, we knew that the dataset has already recorded NA values. Therefore we do not need to do it again. In this section, I want to make the column Distance into a column which only contains numbers, because numeric data is easier to be analysed. So I delete the words in Distance.    
```{r data cleaning}
# remove certain words from Distance 
for(i in 1:nrow(Hostel)){
  Hostel$Distance[i] <- gsub("km from city centre","",Hostel$Distance[i])
}

# change Distance's type into numeric
Hostel$Distance <- as.numeric(Hostel$Distance)
# check the result
str(Hostel)
```
Therefore Distance has been successfully changed into numeric column.

*Note: You may request that score for these sections replace your score for the coding portion of Assignment 3.*

4. Using best practices, write four functions which add engineered features to the dataset, including a description and rationale. Include a test to determine whether the features are working as intended. 

```{r function 1: average rating in different city}
ave_score <- function(data,column){
  data%>%
    group_by(City)%>% # seperate dataset by City
    mutate(ave_rate = ave({{column}},FUN = function(x) mean(x, na.rm = TRUE))) # calculate average score seperately and create a new column called ave_rate
}

# test
ave_score(Hostel,summary.score)
```

```{r function 2: standardize columns}
standardize <- function(data,column){
  data%>%
    mutate(Distance_std = ({{column}} - mean({{column}},na.rm = TRUE))/sd({{column}},na.rm = TRUE)) # standardize the given column and put the standardized result into a new column
}

# test
standardize(Hostel,Distance)
```

```{r function 3: maximum in columns in different city}
maximum <- function(data,column){
  data%>%
    group_by(City)%>%
    mutate(staff_max =  max({{column}},na.rm = TRUE)) # find the maximum and put it into a new column
}

# test
maximum(Hostel,staff)
```

```{r funciton 4: ranking}
ranking <- function(data,column){
  data%>%
    mutate(summaryscore_rank = rank({{column}}, ties.method =c("first"), na.last = TRUE)) # rank the given column and put the result into a new column
}

# test
ranking(Hostel,summary.score)
```


5. Prepare the data for modeling
```{r prepare data}
# save the result of section 4 into dataset Hostel
Hostel <- ave_score(Hostel,summary.score)
Hostel <- standardize(Hostel,Distance)
Hostel <- maximum(Hostel,staff)
Hostel <- ranking(Hostel,summary.score)

# check the final dataset
head(Hostel)
```

Note: this will form the basis for your midterm project. Take advantage of TA's and my office hours. We can provide feedback and guidance. 


